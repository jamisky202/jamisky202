{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "helper_functions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEYPAs4BD4UR"
      },
      "outputs": [],
      "source": [
        "# Unzip the data\n",
        "def unzip_data(zip_dir, unzip_dir=None):\n",
        "  \"\"\"\n",
        "  This model unzip a zip file. It takes in a zipfile and return and unzip file\n",
        "  Args: \n",
        "    zip_dir: The path to the file to be unzipped\n",
        "    unzip_dir: Directory to save the unzip file,\n",
        "              None as a default value\n",
        "  Return:\n",
        "    Null\n",
        "  \"\"\"\n",
        "  import zipfile\n",
        "  zip_ref = zipfile.ZipFile(zip_dir)\n",
        "  zip_ref.extractall(unzip_dir)\n",
        "  zip_ref.close"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Walk through the data\n",
        "def walk_through_directory(directory):\n",
        "  \"\"\"\n",
        "  This model walk through a directory and print the number of directories, files and the directories paths\n",
        "  Args:\n",
        "       directory: The path to the directory to walk through\n",
        "  Return:\n",
        "        Null\n",
        "  \"\"\"\n",
        "  import os\n",
        "  for dirpath, dirnames, filenames in os.walk(directory):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} files/images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "pF0qrZmAGDWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot random images from each class\n",
        "def plot_random_images_from_each_class(train_dir):\n",
        "  \"\"\"\n",
        "  Take in the training directory of a data and display a random image sample from a each class\n",
        "  Args:\n",
        "      train_dir(str): The directory path of the trainning data\n",
        "  Return:\n",
        "      Plot random images from each class of the data\n",
        "  \"\"\"\n",
        "  import os\n",
        "  import random\n",
        "  import matplotlib.pyplot as plt \n",
        "  import matplotlib.image as mpimg \n",
        "\n",
        "  number_of_loop = 0\n",
        "\n",
        "  plt.figure(figsize = (20, 15))\n",
        "  num_classes = len(os.listdir(train_dir))\n",
        "\n",
        "  # Get the subplot shape ready\n",
        "  num_x_images = num_classes/2\n",
        "  if (num_classes%2 == 1):\n",
        "    num_x_images = num_x_images + 1\n",
        "\n",
        "  for data_class in os.listdir(train_dir):\n",
        "    number_of_loop +=1\n",
        "    class_path = train_dir + \"/\" + data_class\n",
        "    random_image_sample = random.choice(os.listdir(class_path))\n",
        "    random_image_sample_path = class_path + \"/\" + random_image_sample\n",
        "\n",
        "    # Load and plot the image\n",
        "    image = mpimg.imread(random_image_sample_path)\n",
        "    plt.subplot(num_x_images, num_x_images, number_of_loop)\n",
        "    plt.imshow(image)\n",
        "    plt.title(data_class)\n",
        "    plt.axis(False)"
      ],
      "metadata": {
        "id": "WzKlqXHYJJka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data into train_data and test_data\n",
        "def load_data(train_dir, test_dir, img_size=(224, 224), class_mode = \"categorical\", batch_size=32):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  import tensorflow as tf\n",
        "\n",
        "  print(\"Loading training data\")\n",
        "  train_data = tf.keras.utils.image_dataset_from_directory(directory=train_dir,\n",
        "                                                           label_mode= class_mode,\n",
        "                                                           image_size= img_size,\n",
        "                                                           batch_size = batch_size)\n",
        "                                                           \n",
        "  print(\"Loading test data\")\n",
        "  test_data = tf.keras.utils.image_dataset_from_directory(directory=test_dir,\n",
        "                                                          label_mode=class_mode,\n",
        "                                                          image_size=img_size,\n",
        "                                                          batch_size=batch_size)\n",
        "  \n",
        "  return train_data, test_data"
      ],
      "metadata": {
        "id": "Uh2F5MzKdUp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_augumented_image(train_dir):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  import os\n",
        "  import random\n",
        "  import matplotlib.pyplot as plt\n",
        "  import matplotlib.image as mpimg\n",
        "  random_class = random.choice(os.listdir(train_dir))\n",
        "  random_class_path = train_dir + \"/\" + random_class\n",
        "  random_image_sample = random.choice(os.listdir(random_class_path))\n",
        "  random_image_sample_path = random_class_path + \"/\" + random_image_sample\n",
        "\n",
        "  # Read in the image\n",
        "  image = mpimg.imread(random_image_sample_path)\n",
        "  aug_image = data_augumentation(image)\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(image)\n",
        "  plt.title(random_class)\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.imshow(aug_image/255.)\n",
        "  plt.title(random_class)\n",
        "  plt.axis(False);\n",
        "\n"
      ],
      "metadata": {
        "id": "9ucuaitydVNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's create function to plt our loss curve\n",
        "def plot_loss_curve(history):\n",
        "  \"\"\"\n",
        "  Return seperate loss curves for loss and accuracy\n",
        "\n",
        "  Args: \n",
        "    history: TensorFlow History object.\n",
        "\n",
        "  Returns:\n",
        "    plot of treaining/validation loss and accuracy metrics\n",
        "  \"\"\"\n",
        "  import pandas as pd\n",
        "  import matplotlib.pyplot as plt\n",
        "  history_dataframe = pd.DataFrame(history.history)\n",
        "  train_loss = history_dataframe[\"loss\"]\n",
        "  val_loss = history_dataframe[\"val_loss\"]\n",
        "  train_accuracy = history_dataframe[\"accuracy\"]\n",
        "  val_accuracy = history_dataframe[\"val_accuracy\"]\n",
        "  epochs = range(len(train_loss))\n",
        "\n",
        "  plt.figure();\n",
        "  plt.plot(epochs, train_loss)\n",
        "  plt.plot(epochs, val_loss)\n",
        "  plt.title(\"loss\")\n",
        "  plt.legend([\"training_loss\", \"val_loss\"])\n",
        "  plt.xlabel(\"epochs\")\n",
        "\n",
        "  plt.figure();\n",
        "  plt.plot(epochs, train_accuracy)\n",
        "  plt.plot(epochs, val_accuracy)\n",
        "  plt.title('Accuracy')\n",
        "  plt.legend([\"training_accuracy\", \"Val_accuracy\"])\n",
        "  plt.xlabel(\"epochs\")\n"
      ],
      "metadata": {
        "id": "YnaOjBsbjOAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "cmBp41D0tXZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensorboard callback\n",
        "def create_tensorboard_callback(directory_name, experiment_name):\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  import tensorflow as tf\n",
        "  import datetime\n",
        "  log_dir = directory_name + \"/\" + experiment_name + datetime.datetime.now().strftime(\"%y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "  print(f\"Saving TensorBoard callback in '{log_dir}'.\")\n",
        "  return tensorboard_callback\n"
      ],
      "metadata": {
        "id": "fcTHOLRMq3d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_checkpoint_callback(checkpoint_path):\n",
        "  import tensorflow as tf\n",
        "  checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                         save_weights_only=True,\n",
        "                                                         save_best_only=False,\n",
        "                                                         save_freq=\"epoch\",\n",
        "                                                         verbose = 1)\n",
        "  return checkpoint_callback"
      ],
      "metadata": {
        "id": "Z8_ToAOQs2De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune(base_model, num_of_ft_layers):\n",
        "  num_of_ft_layers = int(num_of_ft_layers) \n",
        "  base_model.trainable = True\n",
        "  for layers in base_model.layers[:-num_of_ft_layers]:\n",
        "    layers.trainable = False"
      ],
      "metadata": {
        "id": "NcIJjjgys8jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_percent_images(target_dir, new_dir, sample_amount=0.1, random_state=42):\n",
        "    \"\"\"\n",
        "    Get sample_amount percentage of random images from target_dir and copy them to new_dir.\n",
        "    \n",
        "    Preserves subdirectory file names.\n",
        "    \n",
        "    E.g. target_dir=pizza_steak/train/steak/all_files \n",
        "                -> new_dir_name/train/steak/X_percent_of_all_files\n",
        "                \n",
        "    Parameters\n",
        "    --------\n",
        "    target_dir (str) - file path of directory you want to extract images from\n",
        "    new_dir (str) - new directory path you want to copy original images to\n",
        "    sample_amount (float), default 0.1 - percentage of images to copy (e.g. 0.1 = 10%)\n",
        "    random_state (int), default 42 - random seed value \n",
        "    \"\"\"\n",
        "    # Set random seed for reproducibility\n",
        "    import random\n",
        "    import shutil\n",
        "    import os\n",
        "    from tqdm import tqdm\n",
        "    \n",
        "    random.seed(random_state)\n",
        "    \n",
        "    # Get a list of dictionaries of image files in target_dir\n",
        "    # e.g. [{\"class_name\":[\"2348348.jpg\", \"2829119.jpg\"]}]\n",
        "    images = [{dir_name: os.listdir(target_dir + dir_name)} for dir_name in os.listdir(target_dir)]\n",
        "\n",
        "    for i in images:\n",
        "        for k, v in i.items():\n",
        "            # How many images to sample?\n",
        "            sample_number = round(int(len(v)*sample_amount))\n",
        "            print(f\"There are {len(v)} total images in '{target_dir+k}' so we're going to copy {sample_number} to the new directory.\")\n",
        "            print(f\"Getting {sample_number} random images for {k}...\")\n",
        "            random_images = random.sample(v, sample_number)\n",
        "\n",
        "            # Make new dir for each key\n",
        "            new_target_dir = new_dir + k\n",
        "            print(f\"Making dir: {new_target_dir}\")\n",
        "            os.makedirs(new_target_dir, exist_ok=True)\n",
        "\n",
        "            # Keep track of images moved\n",
        "            images_moved = []\n",
        "\n",
        "            # Create file paths for original images and new file target\n",
        "            print(f\"Copying images from: {target_dir}\\n\\t\\t to: {new_target_dir}/\\n\")\n",
        "            for file_name in tqdm(random_images):\n",
        "                og_path = target_dir + k + \"/\" + file_name\n",
        "                new_path = new_target_dir + \"/\" + file_name\n",
        "\n",
        "                # Copy images from OG path to new path\n",
        "                shutil.copy2(og_path, new_path)\n",
        "                images_moved.append(new_path)\n",
        "\n",
        "            # Make sure number of images moved is correct\n",
        "            assert len(os.listdir(new_target_dir)) == sample_number\n",
        "            assert len(images_moved) == sample_number"
      ],
      "metadata": {
        "id": "_24ECbiw2glv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wSpG3oT9-sMU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}